load config from['./Accuracy/config/transformer/config_stt2_bert(large)_ibert_train.ini']
===============================configurations===============================
Section Network   
	 model                : BERT
	 dataset              : GLUE
	 data_path            : /home/wangcong/dataset/glue_data
	 task                 : SST-2
	 pretrained           : True
	 model_path           : /home/wangcong/pretrain/huggingface/hub/models--bert-large-uncased/snapshots/models
Section Quantization
	 mode                 : FloatingPoint
	 embedding            : True
	 weightprecision      : 8
	 inputprecision       : 8
	 biasprecision        : 32
	 errorprecision       : -1
	 gradientprecision    : -1
	 weightsignmapping    : TwosComp
	 inputsignmapping     : TwosComp
	 weightmapping        : Sign
	 inputmapping         : Sign
	 hardware             : False
	 dumpaveragevalue     : False
	 dumpaveragevalue_path : ./log/transformer/SST2/average/
Section Training  
	 batch_size           : 32
	 max_seq_length       : 128
	 learning_rate        : 2e-5
	 bn_learning_rate     : 0.1
	 numepoch             : 5
	 decreasing_lr        : 3, 5
	 train_log_interval   : 100
	 val_log_interval     : 1
Section Inference 
	 finetuned            : False
	 finetuned_model      : /home/wangcong/pretrain/huggingface/hub/models--bert-large-uncased/snapshots/models/SST-2
Section Path      
	 log_dir              : ./log/transformer
	 organize             : Network_model,Network_dataset,Network_task,Quantization_mode
	 tag                  : datadump
Section CIM       
	 arraysize            : 128
	 cellprecision        : 1
	 cycleprecision       : 1
	 digitref2            : True
	 digitref3            : True
	 withcellvar          : False
Section Device    
	 resmap               : ./cimsim/Component/cell_files/fake_device_test.csv
	 gmincancel           : False
Section Debug     
	 printlinearerr       : False
	 printmatmulerr       : False
Section ADC       
	 mode                 : Linear
	 type                 : SAR
	 share                : 8
	 dumpdata             : False
	 dumpdatapath         : dumped_data
	 std_file             : ./ADC_files/Linear_std/test.csv
	 ref_file             : .ADC_files/NLinear_levels/test.csv
	 linear_file          : ./ADC_files/Linear/VGG8/basic/bit9.csv
	 nlinear_file         : ./ADC_files/NLinear_levels/test.csv
	 nlineartype          : KMEANS
Section DMVMCIM   
	 mixedsignal          : True
	 arraysize            : 128
	 cellprecision        : 1
	 cycleprecision       : 1
	 digitref2            : True
	 digitref3            : True
	 withcellvar          : False
Section DMVMDevice
	 resmap               : ./cimsim/Component/cell_files/fake_device_test.csv
	 gmincancel           : False
Section DMVMADC   
	 mode                 : Linear
	 type                 : SAR
	 share                : 8
	 dumpdata             : False
	 dumpdatapath         : dumped_data
	 std_file             : ./cimsim/Component/ADC_files/Linear_std/test.csv
	 ref_file             : ./cimsim/Component/ADC_files/NLinear_levels/test.csv
	 linear_file          : ./cimsim/Component/ADC_files/Linear/BERT/bit7.csv
	 nlinear_file         : ./cimsim/Component/ADC_files/NLinear_levels/test.csv
	 nlineartype          : KMEANS
Section NonIdeal  
	 noiseloc             : None
	 noisetype            : Gaussian
	 noisestd             : 10
	 printstat            : False
	 weightnoise          : 0.0
===============================configurations===============================
BertForSequenceClassification(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 1024, padding_idx=0)
      (position_embeddings): Embedding(512, 1024)
      (token_type_embeddings): Embedding(2, 1024)
      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-23): 24 x BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=1024, out_features=1024, bias=True)
              (key): Linear(in_features=1024, out_features=1024, bias=True)
              (value): Linear(in_features=1024, out_features=1024, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=1024, out_features=1024, bias=True)
              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=1024, out_features=4096, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=4096, out_features=1024, bias=True)
            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=1024, out_features=1024, bias=True)
      (activation): Tanh()
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=1024, out_features=2, bias=True)
)
Train Epoch: 0 [0/4] Loss: 0.0220 Acc: 0.5312 lr:0.000020
